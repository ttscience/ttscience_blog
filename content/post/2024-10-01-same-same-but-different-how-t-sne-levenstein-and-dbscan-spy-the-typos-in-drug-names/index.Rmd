---
title: 'Same-Same, but Different: How t-SNE, Levenshtein  and DBSCAN Spy the Typos in
  Drug Names'
author: Kamil Pytlak
date: '2024-10-01'
categories:
  - machine learning
  - R
  - statistics
  - text analysis
tags:
  - data visualization
  - drug names
  - EDC
  - levenshtein distance
  - NLP
  - t-SNE
slug: same-same-but-different-how-t-sne-levenshtein-and-dbscan-spy-the-typos-in-drug-names
ShowToc: yes
TocOpen: yes
---

# Introduction

## Let's imagine...

... that we need to clean up our client's database for an upcoming interim analysis. We're looking at a lot of data, like patient demographics, patient outcomes (vital signs, physical exam, laboratory parameters), adverse events, and the medications they're taking. Once we load the data in R, it could look like this:

```{r}
set.seed(7)

patient_ids <- sample(1:100, 20, replace = TRUE)

# Create a vector of medication names (with some intentional typos)
medications <- c("Aspirin", "Ibuprofin", "Paracetemol", "Metformn", "Lisinopril", 
                 "Omeprazole", "Metprolol", "Warferin", "Amoxcillin", "Simvastatin")

# Introduce typos by duplicating medication names with variations
medications_typo <- c(medications, "Aspirn", "Ibuprofine", "Paraceteml", "Metformin", 
                      "Lisinorpil", "Omeprazo", "Metoprolol", "Warfarin", "Amoxcilin", "Simavastatin")

# Randomly select medications (including those with typos)
con_meds <- sample(medications_typo, length(patient_ids), replace = TRUE)

con_meds_df <- data.frame(
  patient_id = patient_ids,
  con_med = medications_typo
)

print(con_meds_df)
```

The first column shows the patient ID, and the second column shows the drug they're taking. Some medications are repeated for different patients, which is normal. But some medications have been entered incorrectly, like Aspirin - Aspirn, Ibuprofin - Ibuprofine, and Omeprazole - Omeprazo. Let's look at the uniqueness of drug names:

```{r}
unique(con_meds_df$con_med) |> sort()
```
Do you see what's going on here? In a system that's not quite fully automated, drug names are entered by researchers. These are various researchers who don't have time to check which drug name is officially recognized as a model. Even if they do, it's easy to make a typo, even in the simplest of cases. 


## t-SNE + Distance Metrics = Visualization of Similarity Between Texts

To tackle this problem, we can use text distance metrics like Levenshtein distance, which measures the number of single-character edits needed to transform one string into another. By working out the distances between the drug names, we can spot the subtle differences and similarities between them. But a matrix of distances doesn't give us much insight that we can easily grasp. This is where t-SNE (t-distributed Stochastic Neighbor Embedding) comes in handy. t-SNE lets us turn high-dimensional distance matrices into a 2D visualization, where similar items cluster together. In our example, drug names like "Ibuprofin" and "Ibuprofine" will be grouped together, making the typo patterns immediately visible. So, using t-SNE with distance metrics lets us not only measure how similar texts are, but also see them on a map. This makes it easier to spot inconsistencies in drug names, which is useful for cleaning up data and making sure it's of good quality.

This approach turns a complex problem of detecting subtle textual variations in drug names into a visual pattern-recognition task. Drug names with a lot of typos or different spellings stand out as small, tight clusters. For instance, "Omeprazole" and its variations ("Omeprazo" or "Omeparzole") will form a small group that's distinct from other medications. Similarly, names like "Warfarin" and "Warferin" will also cluster close to each other. The great thing about this visualization is that it can be used not only to identify errors but also to track down systematic inconsistencies across large datasets. Are there recurring typos for certain drugs? Are the same misspellings repeated by different researchers? Such insights can be hard to glean from simple tabular summaries, but they're made obvious when visualized.

What's more, t-SNE isn't just for visualizing individual typos. It can also help you spot more complex patterns. Picture this: multiple versions of drug names are all over the place because of regional spelling differences (like "Amoxicillin" vs. "Amoxycillin") or inconsistent expansion of abbreviations. In these cases, regular text-matching tools might not be able to spot these details, but t-SNE can still show which names are considered similar based on their edit distances. So, the technique takes all those raw string distance calculations and turns them into a more intuitive and user-friendly visual representation. This makes it a really powerful tool for clinical data scientists who need to maintain data integrity.

Finally, combining t-SNE with interactive visualization tools like plotly or ggplot allows users to hover over each data point to see the original names. This lets you quickly explore the clusters and even make changes directly, like flagging incorrect entries or suggesting corrections. This method not only makes data cleaning more efficient but also helps you catch errors in critical analyses. In clinical research, where drug name accuracy can have a big impact, this simple, visual approach is really valuable.


# Case Study: Validation of Drug Names for a Pharmaceutical Gig

## Overview of the Project and its Objectives

We did some detailed validation of eCRF data for one of our company's clients. This included things like demographics, lab results, and even concomitant medications (con-meds). 

> Concomitant drugs refer to the simultaneous or successive use of two or more drugs in order to achieve the purpose of treatment, and the main result is to enhance the drug efficacy or to decrease the drug side effects. (ScienceDirect, https://www.sciencedirect.com/topics/pharmacology-toxicology-and-pharmaceutical-science/concomitant-drug)

In our eCRF system, the researchers entered the drug names by hand. Unfortunately, text and humans don't always work well together. As you probably know, the popular acetylsalicylic acid can be written in a few different ways, including aspirin, salicylic acid, ASA, and... 2-acetoxybenzoic acid.

Have you already figured out what problems this can cause? Computers are pretty simple — to them, "aspirin" and "Aspirin" are two different text strings. So, when we're counting the proportions of patients taking different drugs at different stages of treatment, we'll get two separate proportions for aspirin and Aspirin, even though they're the same drugs.

So what solutions do we have?
- See what unique drugs [`unique(con_meds)`] our database contains, **find errors and just correct them**.
- See what unique drugs [`unique(con_meds)`] our database contains, **calculate the distance between their names, and then visualize them**.

If our database has a relatively small number of con-meds, the first option is probably the easiest. However, the more drugs patients are taking, the more complex it becomes. This is because different drugs can have similar names, and sometimes patients have different characteristics that affect their drug regimen. To quickly and effectively identify duplicates, ambiguities, and errors in drug names, we need a more efficient method. **This is where Levenshtein  and t-SNE come in handy.**


## Let's Do it in R: How to Quickly and Effectively Check the Differences Between Drug Names?

To begin with, we will simulate sample patients and, in particular, the medications they take. To do this, we will use the Anatomical Therapeutic Chemical (ATC) classification system. To scrap this dictionary, I used a script from user fabkury's [atcd](https://github.com/fabkury/atcd) repository on GitHub. The scraped data is current as of 05/09/2024. We also load libraries for data manipulation, visualization, t-SNE and DBSCAN construction.

> In the Anatomical Therapeutic Chemical (ATC) classification system, the active substances are divided into different groups according to the organ or system on which they act and their therapeutic, pharmacological and chemical properties. Drugs are classified in groups at five different levels. (WHO, https://www.who.int/tools/atc-ddd-toolkit/atc-classification)

```{r, message=FALSE}
library(dplyr)
library(stringdist )
library(Rtsne)
library(dbscan)
library(ggrepel)
library(ggplot2)
```


```{r}
atc_df <- read.csv("WHO ATC-DDD 2024-09-05.csv")

head(atc_df, 10)
```

Next, we will extract only drug names (length `atc_code` equal to 7) and draw 100 drug names with possible repetitions.

```{r}
set.seed(7)
drug_names <- atc_df |>
  filter(nchar(atc_code) == 7) |>
  slice_sample(n = 100, replace = TRUE) |>
  pull(atc_name)

unique(drug_names) |> sort()
```

We're looking to add a bit of confusion to our drug names, so we've created a function called `introduce_variation`. It takes a name and returns a new version with a duplicate, deleted, or rearranged character.

```{r}
introduce_variation <- function(name) {
  # Randomly choose a type of modification to introduce a typo
  modification <- sample(c("duplicate", "remove", "swap"), 1)
  name_chars <- unlist(strsplit(name, ""))
  
  if (modification == "duplicate") {
    # Duplicate a random character
    duplicate_pos <- sample(1:length(name_chars), 1)
    name_chars <- append(name_chars, name_chars[duplicate_pos], after = duplicate_pos)
  } else if (modification == "remove") {
    # Remove a random character
    remove_pos <- sample(1:length(name_chars), 1)
    name_chars <- name_chars[-remove_pos]
  } else if (modification == "swap") {
    # Swap two adjacent characters
    swap_pos <- sample(1:(length(name_chars) - 1), 1)
    temp <- name_chars[swap_pos]
    name_chars[swap_pos] <- name_chars[swap_pos + 1]
    name_chars[swap_pos + 1] <- temp
  }
    
  return(paste(name_chars, collapse = ""))
}
```

Each drug name in `drug_names` has a 30% chance of generating a variation, so we'll end up with about 130 drug names instead of 100. We'll also add some drug names from another language (Polish).

```{r}
set.seed(7)
sample_drug_names_with_typos <- sapply(drug_names, function(name) {
  if (runif(1) <= 0.3) {
    introduce_variation(name)
  } else {
    name
  }
})

complete_drug_names <- c(drug_names, sample_drug_names_with_typos)

# Add additional drug names in Polish
complete_drug_names <- c(complete_drug_names, c("Kwas acetylosalicylowy i kortykosteroidy", # acetylsalicylic acid and corticosteroids
                                                "Węglan magnezu", # Magnesium carbonate
                                                "Kwas foliowy" # Folic acid
))

unique(complete_drug_names) |> sort()
```
And now for the most interesting part: we will visualize the names of the drugs on the chart. This is a two-step process:

1. Constructing a $ n \times n $ edit distance matrix between drug names using the Levenshtein  distance metric.
2. Using the t-SNE method to reduce the dimensions from $ n $ to 2 and visualize the embedding vectors.

```{r}
unique_drug_names <- unique(complete_drug_names) |> sort()
```

When it comes to dimensionality reduction methods like t-SNE, it's important to think about a few key hyperparameters that can make a big difference in the resulting vector embeddings and, ultimately, the final visualization. In this case, I'm going to focus on `perplexity`, since it has the biggest impact here.

> A second feature of t-SNE is a tuneable parameter, “perplexity,” which says (loosely) how to balance attention between local and global aspects of your data. The parameter is, in a sense, a guess about the number of close neighbors each point has. The perplexity value has a complex effect on the resulting pictures. The original paper says, “The performance of SNE is fairly robust to changes in the perplexity, and typical values are between 5 and 50.” But the story is more nuanced than that. Getting the most from t-SNE may mean analyzing multiple plots with different perplexities. (Distill, https://distill.pub/2016/misread-tsne/)

In order to select the optimal choice of perplexity, I decided to use the method of its optimization using a modified Bayesian Schwarz information criterion associated with the KL divergence metric. The goal is to minimize $S(Perplexity)$. You can read more about this optimization technique here: [Automatic Selection of t-SNE Perplexity](https://arxiv.org/abs/1708.03229).

```{r}
optimize_perplexity <-
  function(data,
           min_perp = 2,
           max_perp = 20,
           step = 1) {
    final_perp <- 0
    min_kl <- Inf
    n <- nrow(data)
    
    for (perp in seq(min_perp, max_perp, step)) {
      tsne_res <- Rtsne(data, is_distance = TRUE, perplexity = perp)
      
      kl_divergence <- 2 * min(tsne_res$itercosts) + log(n) * (perp / n)
      
      cat("Perplexity:", perp, "| KL Divergence:", kl_divergence, "\n")
      
      if (kl_divergence < min_kl) {
        min_kl <- kl_divergence
        final_perp <- perp
      }
      
      cat("Best Perplexity So Far:", final_perp, "| Best KL Divergence:", min_kl, "\n\n")
    }
    
    return(final_perp)
  }
```

We also want to figure out which drugs are in the same group. Each group should have drugs that are similar to each other in terms of Levenshtein distance. We'll use the DBSCAN algorithm for this. It doesn't require us to specify the number of clusters upfront. It estimates them based on things like `epsilon`. In other words, it's the furthest distance between two samples that determines if they're considered neighbours. For `minPts` I set the value to 2 (can you guess why?). For `epsilon`, on the other hand, I chose 15, which is due to the construction (offstage) of the k-distance plot

```{r}
construct_tsne_with_dbscan <- function(data, max_perp = 20, eps = 15, minPts = 2) {
  # Step 1: Create a Levenshtein distance matrix
  distance_matrix <- stringdistmatrix(data, data, method = "lv")
  rownames(distance_matrix) <- data
  colnames(distance_matrix) <- data
  
  # Step 2: Convert the distance matrix into a format suitable for t-SNE
  distance_mtx <- as.dist(distance_matrix) |> as.matrix()
  
  # Step 3: Optimize the "perplexity" hyperparameter and run t-SNE on the distance matrix
  set.seed(7)
  
  best_perplexity <- optimize_perplexity(distance_mtx, max_perp = max_perp)

  tsne_result <- Rtsne(distance_mtx,
                       is_distance = TRUE,
                       perplexity = best_perplexity)

  # Step 4: Create a data frame with t-SNE results and drug labels
  tsne_df <- data.frame(Dim1 = tsne_result$Y[, 1],
                        Dim2 = tsne_result$Y[, 2],
                        Label = data)

  # Step 5: Perform OPTICS clustering on the t-SNE coordinates
  # Use the t-SNE coordinates for density-based clustering
  dbscan_result <- dbscan(distance_mtx, eps = eps, minPts = minPts)
  
  # Step 6: Add the DBSCAN cluster labels to the data frame
  tsne_df$Cluster <- as.factor(dbscan_result$cluster)
  
  return(tsne_df)
}
```

You'll find the t-SNE result in the graph below. This visualization shows how drug names are grouped together in a two-dimensional space based on how similar they are in terms of their text. Each point shows a drug name, and its position is based on the pairwise Levenshtein distances from the original names. Also, the color of the point shows which cluster it's in. You can see how the points are spread out and close together, which shows clusters of similar names. This could mean that there are some names that are similar but not the same, or that different naming conventions are used. Adding text labels makes it easier to understand what each point represents, so you can quickly identify specific drugs.

```{r, warning=FALSE}
tsne_df <- construct_tsne_with_dbscan(unique_drug_names)

tsne_df |>
    ggplot(aes(x = Dim1, y = Dim2, label = Label)) +
    geom_point(aes(color = Cluster), size = 1) +
  geom_text_repel(aes(label = Label), max.overlaps = 10, size = 2) +
    labs(x = "Dimension 1", y = "Dimension 2") +
    guides(color = "none") +
    theme_bw()
```

This graphic is pretty tricky to make sense of because there are so many data points and drug names that are all jumbled together. So, let's take a look at the DBSCAN clustering result instead:

```{r}
clusters_list <- tsne_df |>
    group_by(Cluster) |>
    summarize(Drugs = paste(Label, collapse = " | ")) |>
    arrange(Cluster)
  
  # Print each cluster and the associated drug names
  for (i in 1:nrow(clusters_list)) {
    cat("Cluster", clusters_list$Cluster[i], ":\n")
    cat(clusters_list$Drugs[i], "\n\n")
  }
```

For instance, cluster 1 includes a wide variety of drugs, such as acetylsalicylic acid and corticosteroids, aminophylline, bupivacaine, and meloxicam.

Clusters like cluster 5, which includes benzoyl peroxide and its misspelled variant benzoly peroxide, show how useful Levenshtein distance can be for identifying typographical errors. Similarly, cluster 6 brings together different spellings of betamethasone.

This clustering analysis helps us understand the relationships among drug names and the potential issues that similar or identical names can cause. This isn't perfect, though. We still need to check if there are any other similar duplicates (take a look at the first cluster). Also, the Levenshtein metric is designed for editing, so it's not ideal for texts in different languages (see "Kwas foliowy" and "folic acid"). But it can definitely streamline our work and automate the process for future reports, and it provides some interesting insights!


# Final Thoughts: Con-meds data in EDC - how to make it clean and meaty?

It's really important to make sure that the data on the drugs people are taking at the same time as the ones being tested (concomitant medications, or "con-meds") is accurate and complete in the systems we use to capture data from clinical trials. To make this happen, we need to automate data entry tasks. Instead of relying on researchers to manually enter drug data, integrating the electronic case report form (eCRF) with a comprehensive drug dictionary, like the WHO Anatomical Therapeutic Chemical (ATC) classification, can make the process a lot more efficient. This integration would make it simple for users to enter or select drug names from a standard list, which would help to avoid errors caused by spelling variations or outdated names. By using these automated solutions, we can make sure that our con-meds data is cleaner and more reliable, which will improve the overall quality of clinical research.